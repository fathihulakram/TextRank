{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\irfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\irfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open AI_summarization.txt article\n",
    "file = open(\"AI_summarization.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open exercise.txt article\n",
    "file = open(\"exercise.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open chatgpt.txt article\n",
    "file = open(\"chatgpt.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open time_travel.txt article\n",
    "file = open(\"time_travel.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open confess.txt article\n",
    "file = open(\"confess.txt\", \"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentences=sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 17\n",
      "Summary sentence: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The future of ChatGPT is a topic of much excitement and speculation in the technology and AI communities.',\n",
       " 'As one of the largest language models developed by OpenAI, ChatGPT has already had a significant impact on the field of natural language processing and has the potential to change the way we interact with computers and technology.',\n",
       " 'In the near future, it is likely that ChatGPT will continue to improve and become even more advanced.',\n",
       " 'As more data and computational power becomes available, the model will be able to process and understand an even larger range of languages, topics, and styles of writing.',\n",
       " 'This will make it even more effective for a variety of tasks, such as language translation, question-answering, and text generation.',\n",
       " 'One of the most exciting applications of ChatGPT in the future is its potential to revolutionize the field of customer service.',\n",
       " 'With its ability to understand and respond to customer inquiries in natural language, ChatGPT could replace human customer service representatives and provide a more efficient and cost-effective solution for businesses.',\n",
       " 'Another area where ChatGPT could have a major impact is in the field of personalization.',\n",
       " 'With its ability to understand and respond to user inputs, ChatGPT could be used to personalize a variety of products and services, such as news feeds, shopping recommendations, and entertainment suggestions.',\n",
       " 'In the long term, it is possible that ChatGPT could even become a key component of the next generation of intelligent personal assistants.',\n",
       " 'By integrating with other AI technologies, such as computer vision and robotics, ChatGPT could form the foundation of a new class of intelligent machines that can interact with us in a natural and intuitive way.',\n",
       " 'However, it is important to note that the future of ChatGPT is not without challenges.',\n",
       " 'One of the biggest challenges will be to ensure that the model is transparent, ethical, and trustworthy.',\n",
       " 'This will require ongoing research and development to address issues such as bias, accountability, and privacy.',\n",
       " 'In conclusion, the future of ChatGPT is both exciting and uncertain.',\n",
       " 'With its potential to revolutionize the way we interact with technology and improve our lives, ChatGPT has the potential to become one of the most important technologies of the 21st century.',\n",
       " 'However, to ensure its success, it will be important to address the challenges that lie ahead and to continue to develop the technology in a responsible and ethical manner.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(Sentences)\n",
    "summary_length = int(length/5)\n",
    "\n",
    "length_str = str(length)\n",
    "sum_length_str = str(summary_length)\n",
    "\n",
    "print(\"Total sentences: \" + length_str)\n",
    "print(\"Summary sentence: \" + sum_length_str)\n",
    "\n",
    "Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_clean=[re.sub(r'[^\\w\\s]','',sentence.lower()) for sentence in Sentences]\n",
    "stop_words = stopwords.words('english')\n",
    "sentence_tokens=[[words for words in sentence.split(' ') if words not in stop_words] for sentence in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['future',\n",
       "  'chatgpt',\n",
       "  'topic',\n",
       "  'much',\n",
       "  'excitement',\n",
       "  'speculation',\n",
       "  'technology',\n",
       "  'ai',\n",
       "  'communities'],\n",
       " ['one',\n",
       "  'largest',\n",
       "  'language',\n",
       "  'models',\n",
       "  'developed',\n",
       "  'openai',\n",
       "  'chatgpt',\n",
       "  'already',\n",
       "  'significant',\n",
       "  'impact',\n",
       "  'field',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'potential',\n",
       "  'change',\n",
       "  'way',\n",
       "  'interact',\n",
       "  'computers',\n",
       "  'technology'],\n",
       " ['near',\n",
       "  'future',\n",
       "  'likely',\n",
       "  'chatgpt',\n",
       "  'continue',\n",
       "  'improve',\n",
       "  'become',\n",
       "  'even',\n",
       "  'advanced'],\n",
       " ['data',\n",
       "  'computational',\n",
       "  'power',\n",
       "  'becomes',\n",
       "  'available',\n",
       "  'model',\n",
       "  'able',\n",
       "  'process',\n",
       "  'understand',\n",
       "  'even',\n",
       "  'larger',\n",
       "  'range',\n",
       "  'languages',\n",
       "  'topics',\n",
       "  'styles',\n",
       "  'writing'],\n",
       " ['make',\n",
       "  'even',\n",
       "  'effective',\n",
       "  'variety',\n",
       "  'tasks',\n",
       "  'language',\n",
       "  'translation',\n",
       "  'questionanswering',\n",
       "  'text',\n",
       "  'generation'],\n",
       " ['one',\n",
       "  'exciting',\n",
       "  'applications',\n",
       "  'chatgpt',\n",
       "  'future',\n",
       "  'potential',\n",
       "  'revolutionize',\n",
       "  'field',\n",
       "  'customer',\n",
       "  'service'],\n",
       " ['ability',\n",
       "  'understand',\n",
       "  'respond',\n",
       "  'customer',\n",
       "  'inquiries',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'chatgpt',\n",
       "  'could',\n",
       "  'replace',\n",
       "  'human',\n",
       "  'customer',\n",
       "  'service',\n",
       "  'representatives',\n",
       "  'provide',\n",
       "  'efficient',\n",
       "  'costeffective',\n",
       "  'solution',\n",
       "  'businesses'],\n",
       " ['another',\n",
       "  'area',\n",
       "  'chatgpt',\n",
       "  'could',\n",
       "  'major',\n",
       "  'impact',\n",
       "  'field',\n",
       "  'personalization'],\n",
       " ['ability',\n",
       "  'understand',\n",
       "  'respond',\n",
       "  'user',\n",
       "  'inputs',\n",
       "  'chatgpt',\n",
       "  'could',\n",
       "  'used',\n",
       "  'personalize',\n",
       "  'variety',\n",
       "  'products',\n",
       "  'services',\n",
       "  'news',\n",
       "  'feeds',\n",
       "  'shopping',\n",
       "  'recommendations',\n",
       "  'entertainment',\n",
       "  'suggestions'],\n",
       " ['long',\n",
       "  'term',\n",
       "  'possible',\n",
       "  'chatgpt',\n",
       "  'could',\n",
       "  'even',\n",
       "  'become',\n",
       "  'key',\n",
       "  'component',\n",
       "  'next',\n",
       "  'generation',\n",
       "  'intelligent',\n",
       "  'personal',\n",
       "  'assistants'],\n",
       " ['integrating',\n",
       "  'ai',\n",
       "  'technologies',\n",
       "  'computer',\n",
       "  'vision',\n",
       "  'robotics',\n",
       "  'chatgpt',\n",
       "  'could',\n",
       "  'form',\n",
       "  'foundation',\n",
       "  'new',\n",
       "  'class',\n",
       "  'intelligent',\n",
       "  'machines',\n",
       "  'interact',\n",
       "  'us',\n",
       "  'natural',\n",
       "  'intuitive',\n",
       "  'way'],\n",
       " ['however',\n",
       "  'important',\n",
       "  'note',\n",
       "  'future',\n",
       "  'chatgpt',\n",
       "  'without',\n",
       "  'challenges'],\n",
       " ['one',\n",
       "  'biggest',\n",
       "  'challenges',\n",
       "  'ensure',\n",
       "  'model',\n",
       "  'transparent',\n",
       "  'ethical',\n",
       "  'trustworthy'],\n",
       " ['require',\n",
       "  'ongoing',\n",
       "  'research',\n",
       "  'development',\n",
       "  'address',\n",
       "  'issues',\n",
       "  'bias',\n",
       "  'accountability',\n",
       "  'privacy'],\n",
       " ['conclusion', 'future', 'chatgpt', 'exciting', 'uncertain'],\n",
       " ['potential',\n",
       "  'revolutionize',\n",
       "  'way',\n",
       "  'interact',\n",
       "  'technology',\n",
       "  'improve',\n",
       "  'lives',\n",
       "  'chatgpt',\n",
       "  'potential',\n",
       "  'become',\n",
       "  'one',\n",
       "  'important',\n",
       "  'technologies',\n",
       "  '21st',\n",
       "  'century'],\n",
       " ['however',\n",
       "  'ensure',\n",
       "  'success',\n",
       "  'important',\n",
       "  'address',\n",
       "  'challenges',\n",
       "  'lie',\n",
       "  'ahead',\n",
       "  'continue',\n",
       "  'develop',\n",
       "  'technology',\n",
       "  'responsible',\n",
       "  'ethical',\n",
       "  'manner']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentence_tokens, vector_size=1, min_count=1, epochs=2000)\n",
    "\n",
    "sentence_embeddings = []\n",
    "for words in sentence_tokens:\n",
    "    sentence_embedding = np.mean([model.wv[word] for word in words], axis=0)\n",
    "    sentence_embeddings.append(sentence_embedding)\n",
    "\n",
    "similarity_matrix = np.zeros([len(sentence_tokens), len(sentence_tokens)])\n",
    "\n",
    "for i, row_embedding in enumerate(sentence_embeddings):\n",
    "    for j, column_embedding in enumerate(sentence_embeddings):\n",
    "        similarity_matrix[i][j] = 1 - spatial.distance.cosine(row_embedding, column_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentence={sentence:scores[index] for index,sentence in enumerate(Sentences)}\n",
    "top=dict(sorted(top_sentence.items(), key=lambda x: x[1], reverse=True)[:summary_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'By integrating with other AI technologies, such as computer vision and robotics, ChatGPT could form the foundation of a new class of intelligent machines that can interact with us in a natural and intuitive way.': 0.058823530442986965,\n",
       " 'One of the biggest challenges will be to ensure that the model is transparent, ethical, and trustworthy.': 0.058823530092371394,\n",
       " 'This will require ongoing research and development to address issues such as bias, accountability, and privacy.': 0.058823530092371394}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By integrating with other AI technologies, such as computer vision and robotics, ChatGPT could form the foundation of a new class of intelligent machines that can interact with us in a natural and intuitive way.\n",
      "One of the biggest challenges will be to ensure that the model is transparent, ethical, and trustworthy.\n",
      "This will require ongoing research and development to address issues such as bias, accountability, and privacy.\n"
     ]
    }
   ],
   "source": [
    "for sent in Sentences:\n",
    "    if sent in top.keys():\n",
    "        print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d14c2ff1705026668e543a26fff62461ba382448a3f283b0896d14e73cf68e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
